{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e11c0d-74fd-4f0b-be26-118846b9c928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 16:41:59.446059: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-19 16:41:59.575121: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-19 16:41:59.580649: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib\n",
      "2023-01-19 16:41:59.580658: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-19 16:41:59.608147: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-19 16:42:00.601206: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib\n",
      "2023-01-19 16:42:00.601257: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib\n",
      "2023-01-19 16:42:00.601262: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-19 16:42:04.849168: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib\n",
      "2023-01-19 16:42:04.849189: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-19 16:42:04.849216: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node0027.palmetto.clemson.edu): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.10.1\n",
      "Eager execution enabled:  False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(40) # suppress deprecation messages\n",
    "tf.compat.v1.disable_v2_behavior() # disable TF2 behaviour as alibi code still relies on TF1 constructs\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from time import time\n",
    "from alibi.datasets import fetch_adult\n",
    "from alibi.explainers import CounterfactualProto\n",
    "from alibi.utils import ohe_to_ord, ord_to_ohe\n",
    "\n",
    "print('TF version: ', tf.__version__)\n",
    "print('Eager execution enabled: ', tf.executing_eagerly()) # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84997461-7fa2-4b26-a001-5a07f06f34ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = fetch_adult()\n",
    "data = adult.data\n",
    "target = adult.target\n",
    "feature_names = adult.feature_names\n",
    "category_map_tmp = adult.category_map\n",
    "target_names = adult.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da45dce-26da-45cb-a836-dc34a6c494cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(s=0):\n",
    "    np.random.seed(s)\n",
    "    tf.random.set_seed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "569c5050-9d0f-4b06-9bf1-a16fd9e357bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "data_perm = np.random.permutation(np.c_[data, target])\n",
    "X = data_perm[:,:-1]\n",
    "y = data_perm[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a661d6a5-c1d5-443d-8405-5f65e185e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx = 30000\n",
    "y_train, y_test = y[:idx], y[idx+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aa120ea-9a86-4add-b2d4-1aef3833d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[X[:, 1:8], X[:, 11], X[:, 0], X[:, 8:11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efe1fe16-429c-4d26-9a60-40b0cb7629b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Workclass', 'Education', 'Marital Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Country', 'Age', 'Capital Gain', 'Capital Loss', 'Hours per week']\n"
     ]
    }
   ],
   "source": [
    "feature_names = feature_names[1:8] + feature_names[11:12] + feature_names[0:1] + feature_names[8:11]\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4595e45-c0c3-4025-9995-5a97f595d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "category_map = {}\n",
    "for i, (_, v) in enumerate(category_map_tmp.items()):\n",
    "    category_map[i] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "429008e0-e001-4d14-9ef9-b3d0c7d498db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 9, 1: 7, 2: 4, 3: 9, 4: 6, 5: 5, 6: 2, 7: 11}\n"
     ]
    }
   ],
   "source": [
    "cat_vars_ord = {}\n",
    "n_categories = len(list(category_map.keys()))\n",
    "for i in range(n_categories):\n",
    "    cat_vars_ord[i] = len(np.unique(X[:, i]))\n",
    "print(cat_vars_ord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b878b07-f709-49f5-b3f7-9d449062a236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 9, 9: 7, 16: 4, 20: 9, 29: 6, 35: 5, 40: 2, 42: 11}\n"
     ]
    }
   ],
   "source": [
    "cat_vars_ohe = ord_to_ohe(X, cat_vars_ord)[1]\n",
    "print(cat_vars_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76230b6e-4b2d-4a76-8851-4b9367218246",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = X[:, -4:].astype(np.float32, copy=False)\n",
    "xmin, xmax = X_num.min(axis=0), X_num.max(axis=0)\n",
    "rng = (-1., 1.)\n",
    "X_num_scaled = (X_num - xmin) / (xmax - xmin) * (rng[1] - rng[0]) + rng[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "521797b2-c02f-4259-9afa-5dce7c7346f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = X[:, :-4].copy()\n",
    "ohe = OneHotEncoder(categories='auto', sparse=False).fit(X_cat)\n",
    "X_cat_ohe = ohe.transform(X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39d40bad-b83b-4c42-8caa-c0b1b0f255eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 57) (2560, 57)\n"
     ]
    }
   ],
   "source": [
    "X = np.c_[X_cat_ohe, X_num_scaled].astype(np.float32, copy=False)\n",
    "X_train, X_test = X[:idx, :], X[idx+1:, :]\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad682302-e033-4c70-bb8a-46e70ca96616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_ohe():\n",
    "    \n",
    "    x_in = Input(shape=(57,))\n",
    "    x = Dense(60, activation='relu')(x_in)\n",
    "    x = Dropout(.2)(x)\n",
    "    x = Dense(60, activation='relu')(x)\n",
    "    x = Dropout(.2)(x)\n",
    "    x = Dense(60, activation='relu')(x)\n",
    "    x = Dropout(.2)(x)\n",
    "    x_out = Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    nn = Model(inputs=x_in, outputs=x_out)\n",
    "    nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ea9955a-c724-430d-ad69-1f98c4a5d284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 57)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 60)                3480      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 60)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 60)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 60)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 122       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,922\n",
      "Trainable params: 10,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 16:42:07.882988: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-19 16:42:07.902057: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1539885f2610>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed()\n",
    "nn = nn_ohe()\n",
    "nn.summary()\n",
    "nn.fit(X_train, to_categorical(y_train), batch_size=256, epochs=30, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89acc887-429f-42fc-9702-c7a424d22fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = X_test[0].reshape((1,) + X_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca9b8bce-36e6-4ca0-a17b-598101045b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = X.shape\n",
    "beta = .01\n",
    "c_init = 1.\n",
    "c_steps = 5\n",
    "max_iterations = 500\n",
    "rng = (-1., 1.)  # scale features between -1 and 1\n",
    "rng_shape = (1,) + data.shape[1:]\n",
    "feature_range = ((np.ones(rng_shape) * rng[0]).astype(np.float32), \n",
    "                 (np.ones(rng_shape) * rng[1]).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baa93ce2-611f-43e9-99b8-842734c69464",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(s=0):\n",
    "    np.random.seed(s)\n",
    "    tf.random.set_seed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62a688ed-99e8-4668-9779-812b2e16a14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "cf = CounterfactualProto(nn,\n",
    "                         shape,\n",
    "                         beta=beta,\n",
    "                         cat_vars=cat_vars_ohe,\n",
    "                         ohe=True,  # OHE flag\n",
    "                         max_iterations=max_iterations,\n",
    "                         feature_range=feature_range,\n",
    "                         c_init=c_init,\n",
    "                         c_steps=c_steps\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8ea66e9-4bfd-4363-940f-58f17a897f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.fit(X_train, d_type='abdm', disc_perc=[25, 50, 75]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf905a09-47bd-49ef-8f78-1c6c75f73882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(dist, cols, figsize=(10,4)):\n",
    "    dist = dist.reshape(dist.shape[0])\n",
    "    idx = np.argsort(dist)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    plt.bar(cols[idx], dist[idx])\n",
    "    print(cols[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84ac3d9d-4fcf-4996-8741-ba90e21df1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dropout' 'High School grad' 'Associates' 'Bachelors' 'Masters'\n",
      " 'Prof-School' 'Doctorate']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat = 'Education'\n",
    "idx = feature_names.index(cat)\n",
    "plot_bar(cf.d_abs[idx], np.array(category_map[idx]), figsize=(20,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db00a1d6-7669-41d1-9449-49563cf04563",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = cf.explain(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36ba0a72-30e2-4ea2-a7c9-48d4897bc130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_instance(X, explanation, eps=1e-2):\n",
    "    print('Original instance: {}  -- proba: {}'.format(target_names[explanation.orig_class],\n",
    "                                                       explanation.orig_proba[0]))\n",
    "    print('Counterfactual instance: {}  -- proba: {}'.format(target_names[explanation.cf['class']],\n",
    "                                                             explanation.cf['proba'][0]))\n",
    "    print('\\nCounterfactual perturbations...')\n",
    "    print('\\nCategorical:')\n",
    "    X_orig_ord = ohe_to_ord(X, cat_vars_ohe)[0]\n",
    "    X_cf_ord = ohe_to_ord(explanation.cf['X'], cat_vars_ohe)[0]\n",
    "    delta_cat = {}\n",
    "    for i, (_, v) in enumerate(category_map.items()):\n",
    "        cat_orig = v[int(X_orig_ord[0, i])]\n",
    "        cat_cf = v[int(X_cf_ord[0, i])]\n",
    "        if cat_orig != cat_cf:\n",
    "            delta_cat[feature_names[i]] = [cat_orig, cat_cf]\n",
    "    if delta_cat:\n",
    "        for k, v in delta_cat.items():\n",
    "            print('{}: {}  -->   {}'.format(k, v[0], v[1]))\n",
    "    print('\\nNumerical:')\n",
    "    delta_num = X_cf_ord[0, -4:] - X_orig_ord[0, -4:]\n",
    "    n_keys = len(list(cat_vars_ord.keys()))\n",
    "    for i in range(delta_num.shape[0]):\n",
    "        if np.abs(delta_num[i]) > eps:\n",
    "            print('{}: {:.2f}  -->   {:.2f}'.format(feature_names[i+n_keys],\n",
    "                                            X_orig_ord[0,i+n_keys],\n",
    "                                            X_cf_ord[0,i+n_keys]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8988fea-9b85-4f72-ba93-5c7b5b0bf04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: <=50K  -- proba: [0.7531671  0.24683289]\n",
      "Counterfactual instance: >50K  -- proba: [0.4991845 0.5008155]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "Country: United-States  -->   Euro_1\n",
      "\n",
      "Numerical:\n"
     ]
    }
   ],
   "source": [
    "describe_instance(X, explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fb5fe53-07b8-48f4-bb8e-b750962720b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: <=50K  -- proba: [0.7531671  0.24683289]\n",
      "Counterfactual instance: >50K  -- proba: [0.4156456  0.58435434]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "Education: Associates  -->   Bachelors\n",
      "\n",
      "Numerical:\n",
      "Capital Gain: -1.00  -->   -0.98\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "cf.fit(X_train, d_type='mvdm')\n",
    "explanation = cf.explain(X)\n",
    "describe_instance(X, explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "520b0620-39f3-4df3-b80f-a2f0dc4f7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_kdtree = True\n",
    "theta = 10.  # weight of prototype loss term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d95b129b-d873-4028-a347-7eaedaf9b51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No encoder specified. Using k-d trees to represent class prototypes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: <=50K  -- proba: [0.536046   0.46395397]\n",
      "Counterfactual instance: >50K  -- proba: [0.44951326 0.5504867 ]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "Education: Bachelors  -->   Prof-School\n",
      "\n",
      "Numerical:\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "X = X_test[7].reshape((1,) + X_test[0].shape)\n",
    "cf = CounterfactualProto(nn,\n",
    "                         shape,\n",
    "                         beta=beta,\n",
    "                         theta=theta,\n",
    "                         cat_vars=cat_vars_ohe,\n",
    "                         ohe=True,\n",
    "                         use_kdtree=use_kdtree,\n",
    "                         max_iterations=max_iterations,\n",
    "                         feature_range=feature_range,\n",
    "                         c_init=c_init,\n",
    "                         c_steps=c_steps\n",
    "                        )\n",
    "cf.fit(X_train, d_type='abdm')\n",
    "explanation = cf.explain(X)\n",
    "describe_instance(X, explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b98d1ac2-22f6-444b-a95d-3856c576a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_model():\n",
    "    # encoder\n",
    "    x_in = Input(shape=(57,))\n",
    "    x = Dense(60, activation='relu')(x_in)\n",
    "    x = Dense(30, activation='relu')(x)\n",
    "    x = Dense(15, activation='relu')(x)\n",
    "    encoded = Dense(10, activation=None)(x)\n",
    "    encoder = Model(x_in, encoded)\n",
    "    \n",
    "    # decoder\n",
    "    dec_in = Input(shape=(10,))\n",
    "    x = Dense(15, activation='relu')(dec_in)\n",
    "    x = Dense(30, activation='relu')(x)\n",
    "    x = Dense(60, activation='relu')(x)\n",
    "    decoded = Dense(57, activation=None)(x)\n",
    "    decoder = Model(dec_in, decoded)\n",
    "    \n",
    "    # autoencoder = encoder + decoder\n",
    "    x_out = decoder(encoder(x_in))\n",
    "    autoencoder = Model(x_in, x_out)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return autoencoder, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "755a245e-3625-41c9-82fc-eff8a5ffc22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 57)]              0         \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, 10)                5935      \n",
      "                                                                 \n",
      " model_2 (Functional)        (None, 57)                5982      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,917\n",
      "Trainable params: 11,917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x153828c40af0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed()\n",
    "ae, enc, dec = ae_model()\n",
    "ae.summary()\n",
    "ae.fit(X_train, X_train, batch_size=128, epochs=100, validation_data=(X_test, X_test), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9006ae24-fe6c-4cfa-ab5a-49c9e0ea38dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = .1  # L1\n",
    "gamma = 10.  # autoencoder\n",
    "theta = .1  # prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e5f7c4e-1bd6-41d0-8735-5260e5961c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: <=50K  -- proba: [0.5141088  0.48589122]\n",
      "Counterfactual instance: >50K  -- proba: [0.42992243 0.57007766]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "Education: High School grad  -->   Associates\n",
      "\n",
      "Numerical:\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "X = X_test[19].reshape((1,) + X_test[0].shape)\n",
    "cf = CounterfactualProto(nn,\n",
    "                         shape,\n",
    "                         beta=beta,\n",
    "                         enc_model=enc,\n",
    "                         ae_model=ae,\n",
    "                         gamma=gamma,\n",
    "                         theta=theta,\n",
    "                         cat_vars=cat_vars_ohe,\n",
    "                         ohe=True,\n",
    "                         max_iterations=max_iterations,\n",
    "                         feature_range=feature_range,\n",
    "                         c_init=c_init,\n",
    "                         c_steps=c_steps\n",
    "                        )\n",
    "cf.fit(X_train, d_type='abdm')\n",
    "explanation = cf.explain(X)\n",
    "describe_instance(X, explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f954988b-40e5-44ad-a5f8-82389951136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_kdtree = True\n",
    "theta = 10.  # weight of prototype loss term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0f1d5c8-af5b-4fc9-83a5-b28d3f3850b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No encoder specified. Using k-d trees to represent class prototypes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: >50K  -- proba: [0.23264737 0.7673526 ]\n",
      "Counterfactual instance: <=50K  -- proba: [0.50304615 0.49695385]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "\n",
      "Numerical:\n",
      "Age: -0.15  -->   -0.17\n",
      "Hours per week: -0.20  -->   -0.50\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "\n",
    "X = X_test[24].reshape((1,) + X_test[0].shape)\n",
    "\n",
    "# define predict function\n",
    "predict_fn = lambda x: nn.predict(x)\n",
    "\n",
    "cf = CounterfactualProto(predict_fn,\n",
    "                         shape,\n",
    "                         beta=beta,\n",
    "                         theta=theta,\n",
    "                         cat_vars=cat_vars_ohe,\n",
    "                         ohe=True,\n",
    "                         use_kdtree=use_kdtree,\n",
    "                         max_iterations=max_iterations,\n",
    "                         feature_range=feature_range,\n",
    "                         c_init=c_init,\n",
    "                         c_steps=c_steps\n",
    "                        )\n",
    "cf.fit(X_train, d_type='abdm')\n",
    "explanation = cf.explain(X)\n",
    "describe_instance(X, explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb8cac-ceea-4cf2-9303-1cb377542799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4cf90c-019c-44f3-8450-454695edceed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083df4d0-71cf-4d8d-b6d0-47910627c6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d2435f-b89d-445a-b7d8-65a96ec500de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8544b3-871b-4e01-881c-baa86b03de76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4bd3db-2e4e-4fa0-bb49-6383a6508d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f4298-15f2-4601-92e2-6decb8bd6758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e634336-9d70-4d2c-86c7-6c1fc2b23e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe30c8-5bec-4d13-87b0-73461a35c0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf77db2-3198-48fa-8c39-ad25ea0eac04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fba7d12-b8f2-49fa-971f-e1a745d466d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868231a7-2510-4702-8b89-06181ca10384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586318d-71b7-4988-897f-2853d2c61a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8e9794-82fd-4f73-b21a-9d68b28922cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848c3ec3-dd8c-495b-862a-f0a165d6940f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e103f719-9bbd-45be-8a11-d2506046809a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c75c2-c46a-461c-bed6-e0275d2753ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6050c42-cb97-49f3-b5fe-885721aa376f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa5828-7972-4d2b-b6e3-9ec0a7f9fbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6f304e-482f-4185-9978-87aba399c844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b24de-e8cf-413d-967c-21280dac57c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864f6c3-0ae4-4e9a-9e8d-67e65db0c95d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
